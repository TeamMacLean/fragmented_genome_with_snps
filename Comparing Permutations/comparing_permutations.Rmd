Methods for comparing contig permutations with a correct order
========================================================

When evaluating the output of the genetic algorithm (GATOC), we need a metric to measure the "correctness" for permutations of the contig order. This is needed to assess how well the fitness method of the algorithm works, as without an increase that is correlated to the "correctness" of contig order, the algorithm cannot be considered effective.

By comparing methods for obtaining such a metric, I aim to find one the one most appropriate for rating the performance of my algorithm.

Metric 1 (Ordinal Similarity)
----

The difference between a contig's index in the correct order and in the permutation, is calculated for each contig. Summing the differences gives an overall score, which can be described mathematically as the ordinal similarity between the two arrangements (correct and a permutation). The higher the value of the score, the lower the ordinal similarity of the permutation to the correct order. A perfect score would be 0, where the permutation being tested is correct. The better permutations generated by the genetic algorithm should have scores closer to 0.

![Image](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/old_or_unused/figures/ordinal_similarity.png?raw=true)

where:
- a = (1...n)  The array of unique objects
- i = each element of a
- F = the function used to generate the rearranged order

Metric 2
------

A new vector is created from the permutation by counting from the position of the first contig (from the correct order) onwards, then adding the rest of the permutation (before the first) to the end of the new vector e.g. [4,3,1,2,5] would translate to [1,2,5,4,3]. The hamming distance for new vector is determined by comparing against the correct order e.g. [1,2,5,4,3] would have a hamming distance of 2 (where [1,2,3,4,5] is the correct order). This hamming distance is then added to the position of the first contig in the permutation minus one (e.g. 2 for [4,3,1,2,5]), to give the final score = 2 + 2 = 4.

GIVE EQUATION

Comparing metrics
----

Below are sparse matrices for all the possible permutations of 3 unique ordered objects (in this case, the integers 1,2 and 3). For each of these permutations I will assign values attributed by the "correctness" metrics.

```{r}
library("Matrix", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
# Metric 1: 0
# Metric 2: 0
as(c(1,2,3), "pMatrix")

# Metric 1: 2
# Metric 2: 2
as(c(1,3,2), "pMatrix")

# Metric 1: 2
# Metric 2: 3
as(c(2,1,3), "pMatrix")

# Metric 1: 4
# Metric 2: 2
as(c(2,3,1), "pMatrix")

# Metric 1: 4
# Metric 2: 1
as(c(3,1,2), "pMatrix")

# Metric 1: 4
# Metric 2: 4
as(c(3,2,1), "pMatrix")
```

The first matrix above shows the correct permutation. The closer each of the other matrices is to the diagonal of ones, the "closer" the permutation must be to the correct order. The degree of "closeness" is what I am trying to establish by providing these metrics. One thing is certain, the reversed permutation ([3,2,1] here) should give the worst possible score, because it is the exact opposite of the correct order. Whilst this is the case for both metric 1 and 2, metric 1 also attributes the same score to two other permutations. Metric 2 takes into account the fact that parts of a permutation may be in consectutive order (objects within a part correctly positioned in relation to eachother), whilst out of step with their correct position in the perfect order. For example, the [2,3,1] and [3,1,2] matrices above have a better metric 2 score than [2,1,3], because they have 2,3 and 1,2 consecutively within them respectively.

```{r}
source('~/fragmented_genome_with_snps/lib/kendall_tau_distance.R')
scores <- as.vector(as.matrix(read.table("~/fragmented_genome_with_snps/test/1-4_metric_scores.txt", quote="\"")))
perms <- as.vector(as.matrix(read.table("~/fragmented_genome_with_snps/test/1-4_perms.txt", quote="\"")))
convert <- function(perm){
  return(strtoi(unlist(strsplit(toString(perm), split=""))))
}
kendallTauDistance(c(1,2,4,3), convert(perms[1]))
kt_scores <- c()
for(perm in perms){
  kt_scores <- c(kt_scores, kendallTauDistance(c(1,2,4,3), convert(perm)))
}

table <- matrix(scores, ncol=5, byrow=TRUE)
colnames(table) <- c("Metric 1","Metric 2a", "Metric 2b", "Metric 2c", "Metrics 1,2 average")#, "Kendall tau distance")
rownames(table) <- perms
table <- as.table(table)
table

table_2 <- matrix(kt_scores, ncol=1, byrow=TRUE)
colnames(table_2) <- c("Kendall tau distance")
rownames(table_2) <- perms
table_2 <- as.table(table_2)
table_2

```

```{r}
as(convert(perms[1]), "pMatrix"); convert(perms[1])
as(convert(perms[2]), "pMatrix"); perms[2]
as(convert(perms[3]), "pMatrix"); perms[3]
as(convert(perms[4]), "pMatrix"); perms[4]
as(convert(perms[5]), "pMatrix"); perms[5]
as(convert(perms[6]), "pMatrix"); perms[6]
as(convert(perms[7]), "pMatrix"); perms[7]
as(convert(perms[8]), "pMatrix"); perms[8]
as(convert(perms[9]), "pMatrix"); perms[9]
as(convert(perms[10]), "pMatrix"); perms[10]
as(convert(perms[11]), "pMatrix"); perms[11]
as(convert(perms[12]), "pMatrix"); perms[12]
as(convert(perms[13]), "pMatrix"); perms[13]
as(convert(perms[14]), "pMatrix"); perms[14]
as(convert(perms[15]), "pMatrix"); perms[15]
as(convert(perms[16]), "pMatrix"); perms[16]
as(convert(perms[17]), "pMatrix"); perms[17]
as(convert(perms[18]), "pMatrix"); perms[18]
as(convert(perms[19]), "pMatrix"); perms[19]
as(convert(perms[20]), "pMatrix"); perms[20]
as(convert(perms[21]), "pMatrix"); perms[21]
as(convert(perms[22]), "pMatrix"); perms[22]
as(convert(perms[23]), "pMatrix"); perms[23]
as(convert(perms[24]), "pMatrix"); perms[24]

```

Evaluating the scores for permutations of length 4 shows that metric 2 has some problems. For example, it gives (4,2,3,1) a higher score (6) than (4,3,2,1) (5), even though the former has 2/4 correctly positioned objects (2 and 3). It also gives (3,4,1,2) a very good score (2) despite none of the objects being correctly positioned; this isn't neccesarily bad, the fact that the sections (3,4) and (1,2) are ordered correctly within has been taken into account.

Averaging the scores of metric 1 and 2 has the following problem: (3,4,2,1) has a higher score (7) than (4,3,2,1) (6.5). This is bad because the (3,4) in the former permutation are correctly ordered realative to eachother.