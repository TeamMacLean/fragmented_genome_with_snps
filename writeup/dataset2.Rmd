A second model genome dataset
========================================================

After running the [rearrangement methods](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/writeup/rearrangement_methods.md) on the [data](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/tree/master/fasta_vcf) generated by my model genome, I realised that the nature of the model genome was potentially limiting the usefulness of the SNP skew methods (left/right methods): see [rearrangement methods](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/writeup/rearrangement_methods.md).

SNP positions in the model genome
---------------------------------

When generating the SNP positions for my model genome in the normal_dist method of [fragments_w_snps.rb](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/fragments_w_snps.rb), I use the [hist](http://stat.ethz.ch/R-manual/R-devel/library/graphics/html/hist.html) function in R (via the [rinruby gem](http://rubygems.org/gems/rinruby)). The breaks argument of the hist function, is used to split the input vector (a random normal distribution, see x below), into a defined number of sections (ranges between the breaks). Each of these ranges has an associated "count", which I use to determine the frequency at which SNP postions should occur within the equivalent section of the model sequence (generated later on). When plotting a histogram, unlike in the example below (plot = FALSE), the number of breaks is the number of cells, and the values in the output $breaks vector are the breakpoints between cells.

```{r}
 x <- rnorm(200000, 100000, 19000)

 hist(x, plot = FALSE)
```

The default value for breaks (input argument) is ["Sturges"](http://stat.ethz.ch/R-manual/R-devel/library/grDevices/html/nclass.html): this invokes uses Sturges' formula, basing the histogram cell sizes (the size of the range between breaks, and by extension the number of breaks), on the range of the data. In this case we can see that the number of breaks is approximately 20 (it can vary with the normal distribution), and that range between each break is 10,000.

The input vector (x) is a random normal distribution of 200,000 values around a mean of 100,000 (with a standard deviation of 19,000). I use this normal distribution to generate a list of SNP positions that can be associated with a 200kb sequence (my model genome). The positions, in this case, are distributed about position 100,000. This is to model a genome from an out-crossed individual with a phenotype altering mutation, as explained in the repo [README](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/README.md), where SNPs are normally distributed about the mutation (in this case position 100,000 of a 200kb sequence). Each histogram cell (section between breaks) generated by the formula above, has an associated count, which as I explained previously, is used to determine the frequency at which SNP postions should occur within the equivalent section of the model sequence.

For each of the ranges between breaks, I randomly generate a number of SNP positions (using the Random class in ruby, see generate_positions method in [fragments_w_snps.rb](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/fragments_w_snps.rb)). The number of positions generated for each range is dependent on the frequency information (counts). So sections of the sequence closer to the centre, have a higher proportion of SNPs compared to sections further from the centre (because in this case, the centre of the normal distribution is the centre of the sequence). For example, the number of SNPs between nucleotide position 100,000 and 110,000 in my 200kb model genome will be higher than the number between 130,000 and 140,00, which in turn will be higher than the number between 0 and 10,000 or 19,000 and 20,000. See the table above for an example of the breaks and counts being generated.

However, the position of SNPs *within* each section (range of the sequence between breaks), is random. It follows then that the higher the number of breaks I specify (in the breaks argument of the hist function), the more closely the SNP positions will follow a normal distribution. This is because a lower number of breaks means larger sections, so the positioning of SNPs across the entire sequence will be affected more by the positioning within each section, and less by the difference in count/frequency *between* the sections of the sequence. 

Herein lies the problem with my model genome, with regard to the skew based method of fragment rearrangement: The fragments being generated in [fragments_w_snps.rb](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/fragments_w_snps.rb) are only 50-250b in length, so whilst the SNP density of each fragment is dependent on it's position in the genome, the skew of SNPs to either side of each fragment is likely to be random. This is because the SNP positions within each 10,000b section of the genome have been placed randomly. 

To deal with this problem I have updated [fragments_w_snps.rb](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/fragments_w_snps.rb), so that the number of breaks in the normal_dist method is 8000:

```{r}
# hist(x, breaks = 8000, plot = FALSE)
```

This splits the histogram into cells with a size of 20 (i.e will represent 20 nucleotides of the sequence). The frequencies (counts) for each 20b section, are used to determine the proportion of SNPs that should be placed in that part of the sequence, in the same way as before. Now that the positions are only random within each 20 nucleotide section of the genome, I expect that fragment's skew will be a more accurate predictor of its location within the model genome.

How closely do the SNP positions follow a normal distribution?
--------------------------------------------------------------

Having updated [fragments_w_snps.rb](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/fragments_w_snps.rb), I ran it along with [json->fasta.rb](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/json-%3Efasta.rb) to create a new dataset: [dataset_2](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/tree/master/fasta_vcf_d2). See [README](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/README.md) for specifics of what fragments_w_snps.rb and json->fasta.rb do.

Before trying out my rearrangement methods on this new dataset, I performed the [Shapiro-Wilk test](http://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) of normality on a list of the SNP positions from the original model genome (dataset_1) and the equivalent list from dataset_2:

```{r}
source("~/fragmented_genome_with_snps/normality_test.txt")
shapiro.test(dataset_1)
shapiro.test(dataset_2)
```

The test shows that for both datasets, we **don't** reject the null hypothesis that the SNP positions **do** follow a normal distribution. This is because the p-values are much higher than any commonly used significance threshold.
The p-value for dataset_2 is close to double that of dataset_1. This shows that the SNP positions in dataset_2 follow a normal curve much more closely than those from dataset_1.


[The results of fragment rearrangement with dataset_2](https://github.com/edwardchalstrey1/fragmented_genome_with_snps/blob/master/writeup/p2_rearrangement_methods.md)
--------------------------------------------------------